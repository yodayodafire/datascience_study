{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8-2 한글 자연어 처리 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한국어 분석을 시작합니다', '재미있어요~~']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.sentences('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한국어', '분석']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.nouns('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('한국어', 'NNG'),\n",
       " ('분석', 'NNG'),\n",
       " ('을', 'JKO'),\n",
       " ('시작하', 'VV'),\n",
       " ('ㅂ니다', 'EFN'),\n",
       " ('재미있', 'VA'),\n",
       " ('어요', 'EFN'),\n",
       " ('~~', 'SW')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.pos('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한국어', '분석', '시작']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hannanum.nouns('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('한국어', 'N'),\n",
       " ('분석', 'N'),\n",
       " ('을', 'J'),\n",
       " ('시작', 'N'),\n",
       " ('하', 'X'),\n",
       " ('ㅂ니다', 'E'),\n",
       " ('재미있', 'P'),\n",
       " ('어요', 'E'),\n",
       " ('~~', 'S')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hannanum.pos('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "t = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한국어', '분석', '시작']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.nouns('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한국어', '분석', '을', '시작', '합니다', '재미있어요', '~~']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.morphs('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('한국어', 'Noun'),\n",
       " ('분석', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('시작', 'Noun'),\n",
       " ('합니다', 'Verb'),\n",
       " ('재미있어요', 'Adjective'),\n",
       " ('~~', 'Punctuation')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.pos('한국어 분석을 시작합니다 재미있어요~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-4. 육아휴직관련 법안 대한민국 국회 제 1809890호 의안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kobill\n",
    "files_ko = kobill.fileids()\n",
    "doc_ko = kobill.open('1809890.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지방공무원법 일부개정법률안\\n\\n(정의화의원 대표발의 )\\n\\n 의 안\\n 번 호\\n\\n9890\\n\\n발의연월일 : 2010.  11.  12.  \\n\\n발  의  자 : 정의화․이명수․김을동 \\n\\n이사철․여상규․안규백\\n\\n황영철․박영아․김정훈\\n\\n김학송 의원(10인)\\n\\n제안이유 및 주요내용\\n\\n  초등학교 저학년의 경우에도 부모의 따뜻한 사랑과 보살핌이 필요\\n\\n한 나이이나, 현재 공무원이 자녀를 양육하기 위하여 육아휴직을 할 \\n\\n수 있는 자녀의 나이는 만 6세 이하로 되어 있어 초등학교 저학년인 \\n\\n자녀를 돌보기 위해서는 해당 부모님은 일자리를 그만 두어야 하고 \\n\\n이는 곧 출산의욕을 저하시키는 문제로 이어질 수 있을 것임.\\n\\n  따라서 육아휴직이 가능한 자녀의 연령을 만 8세 이하로 개정하려\\n\\n는 것임(안 제63조제2항제4호).\\n\\n- 1 -\\n\\n\\x0c법률  제        호\\n\\n지방공무원법 일부개정법률안\\n\\n지방공무원법 일부를 다음과 같이 개정한다.\\n\\n제63조제2항제4호 중 “만 6세 이하의 초등학교 취학 전 자녀를”을 “만 \\n\\n8세 이하(취학 중인 경우에는 초등학교 2학년 이하를 말한다)의 자녀를”\\n\\n로 한다.\\n\\n부      칙\\n\\n이 법은 공포한 날부터 시행한다.\\n\\n- 3 -\\n\\n\\x0c신 ·구조문대비표\\n\\n현      행\\n\\n개   정   안\\n\\n제63조(휴직) ① (생  략)\\n\\n제63조(휴직) ① (현행과 같음)\\n\\n  ② 공무원이 다음 각 호의 어\\n\\n  ② -------------------------\\n\\n느 하나에 해당하는 사유로 휴\\n\\n----------------------------\\n\\n직을 원하면 임용권자는 휴직\\n\\n----------------------------\\n\\n을 명할 수 있다. 다만, 제4호\\n\\n-------------.---------------\\n\\n의 경우에는 대통령령으로 정\\n\\n----------------------------\\n\\n하는 특별한 사정이 없으면 휴\\n\\n----------------------------\\n\\n직을 명하여야 한다.\\n\\n--------------.\\n\\n  1. ∼ 3. (생  략)\\n\\n  1. ∼ 3. (현행과 같음)\\n\\n  4. 만 6세 이하의 초등학교 취\\n\\n  4. 만 8세 이하(취학 중인 경우\\n\\n학 전 자녀를 양육하기 위하\\n\\n에는 초등학교 2학년 이하를 \\n\\n여 필요하거나 여자공무원이 \\n\\n말한다)의 자녀를 ----------\\n\\n임신 또는 출산하게 되었을 \\n\\n---------------------------\\n\\n때\\n\\n---------------------------\\n\\n  5.⋅6. (생  략)\\n\\n  ③⋅④ (생  략)\\n\\n--------\\n\\n  5.⋅6. (현행과 같음)\\n\\n  ③⋅④ (현행과 같음)\\n\\n- 5 -\\n\\n\\x0c지방공무원법 일부개정법률안 등 비용추계서 미첨부사유서\\n1.  재정수반요인\\n\\n개정안에서 ｢국가공무원법｣  제71조제2항제4호 중 국가공무원의 육아\\n\\n휴직 가능 자녀의 연령을 만6세 이하에서 만8세 이하로 하고, ｢지방공\\n\\n무원법｣ 제63조제2항제4호 중 지방공무원의 육아휴직 가능 자녀의 연\\n\\n령을 만6세 이하에서 만8세 이하로 하고, ｢교육공무원법｣ 제44조제1항\\n\\n제7조 중 교육공무원의 육아휴직 가능 자녀의 연령을 만6세 이하에서 \\n\\n만8세 이하로 하고, ｢남녀고용평등과 일․가정 양립지원에 관한 법률｣ \\n\\n제19조제1항 중 근로자 육아휴직 가능 자녀연령을 만6세 이하에서 만\\n\\n8세 이하로 조정함에 따라 추가 재정소요가 예상됨.\\n\\n2.  미첨부  근거  규정\\n｢의안의 비용추계에 관한 규칙｣ 제3조제1항 단서 중 제1호(예상되는 비용이 연평균  10억원 미만\\n이거나  한시적인  경비로서  총  30억원  미만인  경우)에  해당함.\\n\\n3.  미첨부  사유\\n\\n개정안에서 국가․지방․교육공무원 및 근로자가 육아휴직을 신청할 \\n\\n수 있는 자녀의 연령을 만6세 이하에서 만8세 이하로 상향조정함에 \\n\\n따라 추가 재정소요가 예상된다. 동 법률 개정안이 2011년에 시행된다\\n\\n고 가정한 경우, 2010년 현재 자녀의 연령이 7세이고 육아휴직을 신청\\n\\n- 7 -\\n\\n\\x0c- 8 -\\n\\n하지 않은 국가․지방․교육공무원 및 근로자가 대상이 된다.\\n\\n대상연령의 확대됨에 따라 육아휴직신청자의 수가 어느 정도 늘어날 \\n\\n것으로 예상된다. 이 경우 발생하는 비용은 현행법에 따르면 월50만원\\n\\n이나 현재 관련법령 개정이 추진되고 있으며, 이에 따라 2011년에는 \\n\\n육아휴직자가 지급받는 월급여액에 비례하여 육아휴직급여가 지급되\\n\\n기 때문에 법령개정을 가정하고 추계한다. 이러한 경우 육아휴직급여\\n\\n액은 육아휴직자가 지급받는 월급여의 40%에 해당한다. 육아휴직자가 \\n\\n발생한 경우 발생하는 비용은 대체인력 고용인건비와 육아휴직자가 \\n\\n받는 월급여액의 40%이다. 이와 대비하여 육아휴직자에게 지급하던 \\n\\n임금은 더 이상 발생하지 않는다. 따라서 실제 발생하는 순비용은 육\\n\\n아휴직자에게 지급하던 월 급여액과 연령 확대에 따라 발생하는 비용\\n\\n인 육아휴직자가 받던 월급여액의 40%와 대체인력 고용인건비의 차\\n\\n액인데 이 값이 0보다 크면 추가 재정소요는 발생하지 않는다고 볼 \\n\\n수 있다.\\n\\n추가비용 발생여부를 정확하게 알아보기 위하여 비용에 대한 수리모\\n\\n델을 만들고 이에 따라 비용발생 여부를 알아보기로 하자. 모델에 사\\n\\n용되는 변수를 다음과 같이 정의한다.\\n\\n발생비용 : N×p×X + N×육아휴직급여액 - N×P\\n\\nN\\n\\nP\\n\\n: 육아휴직대상자의 수\\n\\n: 육아휴직대상자의 월급여액\\n\\n\\x0cp\\n\\nX\\n\\n: 육아휴직자가 발생한 경우 대체 고용할 확률\\n\\n: 대체 고용한 인력에게 지급하는 월급여액\\n\\n위의 수식에서 육아휴직급여액은 육아휴직자 월급여액의 40%까지 지\\n\\n급할 예정이므로 육아휴직급여액은 P×40%이다. 육아휴직자가 발생한 \\n\\n경우 대체 고용할 확률 p는 고용노동부의 육아휴직 관련 자료를 이용\\n\\n한다. 고용노동부에 따르면 2011년의 경우 육아휴직급여 대상자는 \\n\\n40,923명이며, 육아휴직에 따른 대체인력 고용 예상인원은 2,836명이\\n\\n다. 2007년부터 2011년까지의 현황을 정리하면 다음의 [표]와 같다.\\n\\n[표]  육아휴직급여  수급자의  수  및  대체인력  고용  현황:  2007~2011년\\n\\n(단위:  명,  % )\\n\\n2007\\n\\n2008\\n\\n2009\\n\\n2010\\n\\n2011\\n\\n평균\\n\\n육아휴직급여  수급자(A)\\n\\n21,185\\n\\n29,145\\n\\n35,400\\n\\n41,291\\n\\n43,899\\n\\n34,184\\n\\n대체인력  채용(B)\\n\\n796\\n\\n1,658\\n\\n1,957\\n\\n2,396\\n\\n2,836\\n\\n1,929\\n\\n비  율(B/A)\\n\\n3.8\\n\\n5.7\\n\\n5.5\\n\\n5.8\\n\\n6.5\\n\\n5.6\\n\\n자료: 고용노동부  자료를  바탕으로  국회예산정책처  작성\\n\\n위의 [표]의 자료에 따라 육아휴직자가 발생한 경우 대체 고용할 확률 \\n\\np의 값은 5.6%라고 가정한다. 그리고 비용이 발생한다고 가정하여 위\\n\\n의 수식을 다시 작성하면 다음의 수식과 같다.\\n\\nN×p×X + N×육아휴직급여액 - N×P > 0\\n\\n(1)\\n\\n- 9 -\\n\\n\\x0c- 10 -\\n\\nN×5.6%×X + N×P×40% - N×P > 0\\n\\n0.056×X > 0.6P\\n\\nX > 10.7×P\\n\\n(2)\\n\\n(3)\\n\\n(5)\\n\\n위의 수식에 육아휴직자가 받는 월 급여액을 대입하여 대체고용인력\\n\\n자에게 지급하는 월 급여액을 추정하여 보자. 육아휴직자가 월 200만\\n\\n원을 받는다고 가정하면, 대체고용인력자에게 육아휴직자가 받는 월 \\n\\n급여액의 10.7배에 달하는 월 21,428,571원 이상을 지급해야 추가 비용\\n\\n이 발생한다. 대체고용인력자에게 육아휴직자보다 더 많은 월급여액을 \\n\\n주지는 않을 것이고 그리고 10여배 이상 월급을 주지도 않을 것이기 \\n\\n때문에 추가 비용이 발생한다고 보기 힘들다. 위의 수식에서 대체인력 \\n\\n고용확률 p를 20%로 가정하더라도(이 경우 X > 3×P) 200만원 받는 \\n\\n육아휴직자 대체인력에게 월 600만원 이상을 지급해야 추가 비용이 \\n\\n발생한다.\\n\\n행정안전부의 통계자료(행정안전부 통계연감)에서는 지방공무원의 육\\n\\n아휴직 현황자료를 보여주고 있다. 여기서 육아휴직자가 발생한 경우 \\n\\n대체인력을 주로 임용대기자 또는 일용직을 활용하는 것으로 보인다. \\n\\n따라서 공무원의 경우에도 [표]에서 보여주는 일반기업체의 대체인력 \\n\\n고용확률과 차이는 크지 않을 것으로 보인다.\\n\\n이상의 논의를 바탕으로 육아휴직기간을 만6에서 만8세로 연장하더라\\n\\n도 법률 개정에 따른 추가 비용은 발생하지 않을 것으로 예상된다.\\n\\n\\x0c4.  작성자\\n\\n국회예산정책처 법안비용추계1팀\\n\\n팀      장   정 문 종\\n\\n예산분석관   김 태 완\\n\\n(02-788-4649, tanzania@assembly.go.kr)\\n\\n- 11 -\\n\\n\\x0c'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['지방공무원법',\n",
       " '일부',\n",
       " '개정',\n",
       " '법률',\n",
       " '안',\n",
       " '정의화',\n",
       " '의원',\n",
       " '대표',\n",
       " '발의',\n",
       " '의',\n",
       " '안',\n",
       " '번',\n",
       " '호',\n",
       " '발의',\n",
       " '연월일',\n",
       " '발',\n",
       " '의',\n",
       " '자',\n",
       " '정의화',\n",
       " '이명수',\n",
       " '김을동',\n",
       " '이사철',\n",
       " '여상규',\n",
       " '안규백',\n",
       " '황영철',\n",
       " '박영아',\n",
       " '김정훈',\n",
       " '김학송',\n",
       " '의원',\n",
       " '인',\n",
       " '제안',\n",
       " '이유',\n",
       " '및',\n",
       " '내용',\n",
       " '초등학교',\n",
       " '저학년',\n",
       " '경우',\n",
       " '부모',\n",
       " '사랑',\n",
       " '필요',\n",
       " '나이',\n",
       " '현재',\n",
       " '공무원',\n",
       " '자녀',\n",
       " '양육',\n",
       " '위',\n",
       " '육아휴직',\n",
       " '수',\n",
       " '자녀',\n",
       " '나이',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '초등학교',\n",
       " '저학년',\n",
       " '자녀',\n",
       " '위',\n",
       " '해당',\n",
       " '부모님',\n",
       " '일자리',\n",
       " '곧',\n",
       " '출산',\n",
       " '의욕',\n",
       " '저하',\n",
       " '문제',\n",
       " '수',\n",
       " '것임',\n",
       " '따라서',\n",
       " '육아휴직',\n",
       " '자녀',\n",
       " '연령',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '개정',\n",
       " '것임',\n",
       " '안',\n",
       " '제',\n",
       " '항제',\n",
       " '호',\n",
       " '법률',\n",
       " '제',\n",
       " '호',\n",
       " '지방공무원법',\n",
       " '일부',\n",
       " '개정',\n",
       " '법률',\n",
       " '안',\n",
       " '지방공무원법',\n",
       " '일부',\n",
       " '다음',\n",
       " '개정',\n",
       " '제',\n",
       " '항제',\n",
       " '호',\n",
       " '중',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '초등학교',\n",
       " '취학',\n",
       " '전',\n",
       " '자녀',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '취학',\n",
       " '중인',\n",
       " '경우',\n",
       " '초등학교',\n",
       " '학년',\n",
       " '이하',\n",
       " '말',\n",
       " '의',\n",
       " '자녀',\n",
       " '로',\n",
       " '부',\n",
       " '칙',\n",
       " '이',\n",
       " '법',\n",
       " '공포',\n",
       " '날',\n",
       " '시행',\n",
       " '신',\n",
       " '구조',\n",
       " '문대비',\n",
       " '표',\n",
       " '현',\n",
       " '행',\n",
       " '개',\n",
       " '정',\n",
       " '안',\n",
       " '제',\n",
       " '휴직',\n",
       " '생',\n",
       " '략',\n",
       " '제',\n",
       " '휴직',\n",
       " '현행',\n",
       " '공무원',\n",
       " '다음',\n",
       " '각',\n",
       " '호의',\n",
       " '느',\n",
       " '하나',\n",
       " '해당',\n",
       " '사유',\n",
       " '직',\n",
       " '임용',\n",
       " '휴직',\n",
       " '명',\n",
       " '수',\n",
       " '다만',\n",
       " '제',\n",
       " '호',\n",
       " '의',\n",
       " '경우',\n",
       " '대통령령',\n",
       " '정',\n",
       " '사정',\n",
       " '직',\n",
       " '명',\n",
       " '생',\n",
       " '략',\n",
       " '현행',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '초등학교',\n",
       " '취',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '취학',\n",
       " '중인',\n",
       " '경우',\n",
       " '학',\n",
       " '전',\n",
       " '자녀',\n",
       " '양육',\n",
       " '위',\n",
       " '초등학교',\n",
       " '학년',\n",
       " '이하',\n",
       " '여',\n",
       " '여자',\n",
       " '공무원',\n",
       " '말',\n",
       " '의',\n",
       " '자녀',\n",
       " '임신',\n",
       " '출산',\n",
       " '때',\n",
       " '생',\n",
       " '략',\n",
       " '생',\n",
       " '략',\n",
       " '현행',\n",
       " '현행',\n",
       " '지방공무원법',\n",
       " '일부',\n",
       " '개정',\n",
       " '법률',\n",
       " '안',\n",
       " '등',\n",
       " '비용',\n",
       " '추계',\n",
       " '첨부',\n",
       " '사유',\n",
       " '재정',\n",
       " '요인',\n",
       " '개정안',\n",
       " '국가공무원',\n",
       " '법',\n",
       " '제',\n",
       " '항제',\n",
       " '호',\n",
       " '중',\n",
       " '국가공무원',\n",
       " '육아',\n",
       " '휴직',\n",
       " '가능',\n",
       " '자녀',\n",
       " '연령',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '방공',\n",
       " '무',\n",
       " '법',\n",
       " '제',\n",
       " '항제',\n",
       " '호',\n",
       " '중',\n",
       " '지방',\n",
       " '공무원',\n",
       " '육아휴직',\n",
       " '가능',\n",
       " '자녀',\n",
       " '연',\n",
       " '령',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '교육',\n",
       " '공무원',\n",
       " '법',\n",
       " '제',\n",
       " '항',\n",
       " '제',\n",
       " '중',\n",
       " '교육',\n",
       " '공무원',\n",
       " '육아휴직',\n",
       " '가능',\n",
       " '자녀',\n",
       " '연령',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '남녀',\n",
       " '고용',\n",
       " '평등',\n",
       " '일',\n",
       " '가정',\n",
       " '양립',\n",
       " '지원',\n",
       " '관',\n",
       " '법률',\n",
       " '제',\n",
       " '항',\n",
       " '중',\n",
       " '근로자',\n",
       " '육아휴직',\n",
       " '가능',\n",
       " '자녀',\n",
       " '연령',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '조정',\n",
       " '함',\n",
       " '추가',\n",
       " '재정',\n",
       " '요가',\n",
       " '예상',\n",
       " '첨부',\n",
       " '근거',\n",
       " '규정',\n",
       " '의안',\n",
       " '비용',\n",
       " '추계',\n",
       " '관',\n",
       " '규칙',\n",
       " '제',\n",
       " '항',\n",
       " '단서',\n",
       " '중',\n",
       " '제',\n",
       " '호',\n",
       " '예상',\n",
       " '비용',\n",
       " '평균',\n",
       " '미만',\n",
       " '거나',\n",
       " '한시',\n",
       " '경비',\n",
       " '로서',\n",
       " '총',\n",
       " '미만',\n",
       " '경우',\n",
       " '해당',\n",
       " '함',\n",
       " '첨부',\n",
       " '사유',\n",
       " '개정안',\n",
       " '국가',\n",
       " '지방',\n",
       " '교육',\n",
       " '공무원',\n",
       " '및',\n",
       " '근로자',\n",
       " '육아휴직',\n",
       " '신청',\n",
       " '수',\n",
       " '자녀',\n",
       " '연령',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '만',\n",
       " '세',\n",
       " '이하',\n",
       " '상향',\n",
       " '조정',\n",
       " '함',\n",
       " '추가',\n",
       " '재정',\n",
       " '요가',\n",
       " '예상',\n",
       " '법률',\n",
       " '개정안',\n",
       " '시행',\n",
       " '고',\n",
       " '가정',\n",
       " '경우',\n",
       " '현재',\n",
       " '자녀',\n",
       " '연령',\n",
       " '세이',\n",
       " '육아휴직',\n",
       " '신청',\n",
       " '국가',\n",
       " '지방',\n",
       " '교육',\n",
       " '공무원',\n",
       " '및',\n",
       " '근로자',\n",
       " '대상',\n",
       " '대상',\n",
       " '연령',\n",
       " '확대',\n",
       " '육아휴직',\n",
       " '신청',\n",
       " '수가',\n",
       " '정도',\n",
       " '것',\n",
       " '예상',\n",
       " '이',\n",
       " '경우',\n",
       " '발생',\n",
       " '비용',\n",
       " '현행법',\n",
       " '월',\n",
       " '이나',\n",
       " '현재',\n",
       " '관련',\n",
       " '법령',\n",
       " '개정',\n",
       " '추진',\n",
       " '이',\n",
       " '육아휴직',\n",
       " '지급',\n",
       " '월급',\n",
       " '액',\n",
       " '비례',\n",
       " '육아휴직',\n",
       " '여가',\n",
       " '지급',\n",
       " '기',\n",
       " '때문',\n",
       " '법령',\n",
       " '개정',\n",
       " '가정',\n",
       " '추계',\n",
       " '경우',\n",
       " '육아휴직',\n",
       " '급여',\n",
       " '액',\n",
       " '육아휴직',\n",
       " '지급',\n",
       " '월급',\n",
       " '여의',\n",
       " '해당',\n",
       " '육아휴직',\n",
       " '발생',\n",
       " '경우',\n",
       " '발생',\n",
       " '비용',\n",
       " '체인',\n",
       " '고용',\n",
       " '인건비',\n",
       " '육아휴직',\n",
       " '월급',\n",
       " '액',\n",
       " '이',\n",
       " '대비',\n",
       " '육아휴직',\n",
       " '지급',\n",
       " '임금',\n",
       " '더',\n",
       " '이상',\n",
       " '발생',\n",
       " '따라서',\n",
       " '실제',\n",
       " '발생',\n",
       " '비용',\n",
       " '육',\n",
       " '휴직',\n",
       " '지급',\n",
       " '월',\n",
       " '급여',\n",
       " '액',\n",
       " '연령',\n",
       " '확대',\n",
       " '발생',\n",
       " '비용',\n",
       " '인',\n",
       " '육아휴직',\n",
       " '월급',\n",
       " '액',\n",
       " '체인',\n",
       " '고용',\n",
       " '인건비',\n",
       " '차',\n",
       " '액',\n",
       " '이',\n",
       " '값',\n",
       " '추가',\n",
       " '재정',\n",
       " '소요',\n",
       " '발생',\n",
       " '볼',\n",
       " '수',\n",
       " '추가',\n",
       " '비용',\n",
       " '발생',\n",
       " '여부',\n",
       " '위',\n",
       " '비용',\n",
       " '대한',\n",
       " '리모',\n",
       " '델',\n",
       " '이',\n",
       " '비용',\n",
       " '발생',\n",
       " '여부',\n",
       " '하자',\n",
       " '모델',\n",
       " '사',\n",
       " '용',\n",
       " '변수',\n",
       " '다음',\n",
       " '정의',\n",
       " '발생',\n",
       " '비용',\n",
       " '육아휴직',\n",
       " '액',\n",
       " '육아휴직',\n",
       " '대상자',\n",
       " '수',\n",
       " '육아휴직',\n",
       " '대상자',\n",
       " '월급',\n",
       " '액',\n",
       " '육아휴직',\n",
       " '발생',\n",
       " '경우',\n",
       " '대체',\n",
       " '고용',\n",
       " '확률',\n",
       " '대체',\n",
       " '고용',\n",
       " '인력',\n",
       " '지급',\n",
       " '월급',\n",
       " '액',\n",
       " '위',\n",
       " '수식',\n",
       " '육아휴직',\n",
       " '액',\n",
       " '육아휴직',\n",
       " '월급',\n",
       " '액',\n",
       " '예정',\n",
       " '므',\n",
       " '육아휴직',\n",
       " '액',\n",
       " '육아휴직',\n",
       " '발생',\n",
       " '경우',\n",
       " '대체',\n",
       " '고용',\n",
       " '확률',\n",
       " '고용노동부',\n",
       " '육아휴직',\n",
       " '관련',\n",
       " '자료',\n",
       " '이용',\n",
       " '고용노동부',\n",
       " '경우',\n",
       " '육아휴직',\n",
       " '급여',\n",
       " '대상자',\n",
       " '명',\n",
       " '육아휴직',\n",
       " '체인',\n",
       " '고용',\n",
       " '상인',\n",
       " '명',\n",
       " '현황',\n",
       " '정리',\n",
       " '다음',\n",
       " '표',\n",
       " '표',\n",
       " '육아휴직',\n",
       " '급여',\n",
       " '수급',\n",
       " '수',\n",
       " '및',\n",
       " '체인',\n",
       " '고용',\n",
       " '현황',\n",
       " '단위',\n",
       " '명',\n",
       " '평균',\n",
       " '육아휴직',\n",
       " '급여',\n",
       " '수급',\n",
       " '체인',\n",
       " '채용',\n",
       " '비',\n",
       " '율',\n",
       " '자료',\n",
       " '고용노동부',\n",
       " '자료',\n",
       " '바탕',\n",
       " '국회예산정책처',\n",
       " '작성',\n",
       " '위',\n",
       " '표',\n",
       " '의',\n",
       " '자료',\n",
       " '육아휴직',\n",
       " '발생',\n",
       " '경우',\n",
       " '대체',\n",
       " '고용',\n",
       " '확률',\n",
       " '의',\n",
       " '값',\n",
       " '가정',\n",
       " '비용',\n",
       " '발생',\n",
       " '가정',\n",
       " '위',\n",
       " '의',\n",
       " '수식',\n",
       " '다시',\n",
       " '작성',\n",
       " '다음',\n",
       " '수식',\n",
       " '육아휴직',\n",
       " '액',\n",
       " '위',\n",
       " '수식',\n",
       " '육아휴직',\n",
       " '월',\n",
       " '급여',\n",
       " '액',\n",
       " '대입',\n",
       " '대체',\n",
       " '고용',\n",
       " '인력',\n",
       " '자',\n",
       " '지급',\n",
       " '월',\n",
       " '급여',\n",
       " '액',\n",
       " '추정',\n",
       " '육아휴직',\n",
       " '월',\n",
       " '원',\n",
       " '가정',\n",
       " '대체',\n",
       " '고용',\n",
       " '인력',\n",
       " '육아휴직',\n",
       " '월',\n",
       " '급여',\n",
       " '액',\n",
       " '배',\n",
       " '달',\n",
       " '월',\n",
       " '이상',\n",
       " '지급',\n",
       " '추가',\n",
       " '비용',\n",
       " '이',\n",
       " '발생',\n",
       " '대체',\n",
       " '고용',\n",
       " '인력',\n",
       " '육아휴직',\n",
       " '더',\n",
       " '월급',\n",
       " '액',\n",
       " '주지',\n",
       " '것',\n",
       " '배',\n",
       " '이상',\n",
       " '월급',\n",
       " '주지',\n",
       " '것',\n",
       " '이기',\n",
       " '때문',\n",
       " '추가',\n",
       " '비용',\n",
       " '발생',\n",
       " '보기',\n",
       " '위',\n",
       " '수식',\n",
       " '체인',\n",
       " '고용',\n",
       " '확률',\n",
       " '를',\n",
       " '로',\n",
       " '가정',\n",
       " '이',\n",
       " '경우',\n",
       " '육아휴직',\n",
       " '체인',\n",
       " '월',\n",
       " '이상',\n",
       " '지급',\n",
       " '추가',\n",
       " '비용',\n",
       " '발생',\n",
       " '행정안전부',\n",
       " '통계',\n",
       " '자료',\n",
       " '행정안전부',\n",
       " '통계',\n",
       " '연감',\n",
       " '지방',\n",
       " '공무원',\n",
       " '육',\n",
       " '휴직',\n",
       " '현황',\n",
       " '자료',\n",
       " '여기',\n",
       " '육아휴직',\n",
       " '발생',\n",
       " '경우',\n",
       " '체인',\n",
       " '주로',\n",
       " '임용',\n",
       " '기자',\n",
       " '일용직',\n",
       " '활용',\n",
       " '것',\n",
       " '따라서',\n",
       " '공무원',\n",
       " '경우',\n",
       " '표',\n",
       " '기업체',\n",
       " '체인',\n",
       " '고용',\n",
       " '확률',\n",
       " '것',\n",
       " '이상',\n",
       " '논의',\n",
       " '바탕',\n",
       " '육아휴직',\n",
       " '기간',\n",
       " '만',\n",
       " '만',\n",
       " '세로',\n",
       " '연장',\n",
       " '도',\n",
       " '법률',\n",
       " '개정',\n",
       " '추가',\n",
       " '비용',\n",
       " '발생',\n",
       " '것',\n",
       " '예상',\n",
       " '작성자',\n",
       " '국회예산정책처',\n",
       " '법안',\n",
       " '비용',\n",
       " '추계',\n",
       " '팀',\n",
       " '팀',\n",
       " '장',\n",
       " '정',\n",
       " '문',\n",
       " '종',\n",
       " '예산',\n",
       " '분석관',\n",
       " '김',\n",
       " '태',\n",
       " '완']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt; t = Okt()\n",
    "tokens_ko = t.nouns(doc_ko)\n",
    "tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = nltk.Text(tokens_ko, name='대한민국 국회 의안 제 1809890호')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735\n",
      "250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'육아휴직': 38, '발생': 19, '만': 18, '이하': 18, '비용': 17, '액': 17, '경우': 16, '세': 16, '자녀': 14, '고용': 14, ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ko.tokens))           # returns number of tokens (document length)\n",
    "print(len(set(ko.tokens)))   # returns number of unique tokens\n",
    "ko.vocab()                        # returns frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2e09ade36ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mko\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ko.plot(50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-5. Naive Bayes Classifier의 이해 - 영문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('i like you', 'pos'), \n",
    "         ('i hate you', 'neg'), \n",
    "         ('you like me', 'neg'),\n",
    "         ('i like her', 'pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/tyrus/nltk_data'\n    - '/Users/tyrus/DataScience/nltk_data'\n    - '/Users/tyrus/DataScience/share/nltk_data'\n    - '/Users/tyrus/DataScience/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-313af926d735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-313af926d735>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/tyrus/nltk_data'\n    - '/Users/tyrus/DataScience/nltk_data'\n    - '/Users/tyrus/DataScience/share/nltk_data'\n    - '/Users/tyrus/DataScience/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "set(worl.lower() for sentence in train for word in word_tokenize(sentence[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/tyrus/nltk_data'\n    - '/Users/tyrus/DataScience/nltk_data'\n    - '/Users/tyrus/DataScience/share/nltk_data'\n    - '/Users/tyrus/DataScience/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-38b9b8a0d02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-38b9b8a0d02c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DataScience/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/tyrus/nltk_data'\n    - '/Users/tyrus/DataScience/nltk_data'\n    - '/Users/tyrus/DataScience/share/nltk_data'\n    - '/Users/tyrus/DataScience/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train \n",
    "                for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-9d96f45f7af4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                         for x in train]\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-9d96f45f7af4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                         for x in train]\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_words' is not defined"
     ]
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n",
    "                                                        for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate': False,\n",
       " 'her': False,\n",
       " 'i': True,\n",
       " 'like': True,\n",
       " 'me': False,\n",
       " 'you': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'i like MeRui'\n",
    "test_sent_features = {word.lower(): \n",
    "                                          (word in word_tokenize(test_sentence.lower()))\n",
    "                                           for word in all_words}\n",
    "test_sent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-6. Naive Bayes Classifier의 이해 - 한글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('메리가 좋아', 'pos'), \n",
    "         ('고양이도 좋아', 'pos'),\n",
    "         ('난 수업이 지루해', 'neg'),\n",
    "         ('메리는 이쁜 고양이야', 'pos'),\n",
    "         ('난 마치고 메리랑 놀거야', 'pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-579272af2f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m all_words = set(word.lower() for sentence in train\n\u001b[0m\u001b[1;32m      2\u001b[0m                         for word in word_tokenize(sentence[0]))\n\u001b[1;32m      3\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-579272af2f32>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m all_words = set(word.lower() for sentence in train\n\u001b[0;32m----> 2\u001b[0;31m                         for word in word_tokenize(sentence[0]))\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "all_words = set(word.lower() for sentence in train\n",
    "                        for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
